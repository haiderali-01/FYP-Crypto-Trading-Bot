# -*- coding: utf-8 -*-
"""MultiModal_Fusion.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pQwMWIFC5QW2LaxVqqqLjeOM38j9La2u
"""

import pandas as pd
import numpy as np
import os
from google.colab import drive

drive.mount('/content/drive')
PROJECT_DIR_PATH = '/content/drive/My Drive/FYP DATAETS'

data_file_path = os.path.join(PROJECT_DIR_PATH, "news_data.csv")
if os.path.exists(data_file_path):
    try:
        news_data_df = pd.read_csv(data_file_path, encoding='utf-8')
    except UnicodeDecodeError:
        news_data_df = pd.read_csv(data_file_path, encoding='latin1')
    news_data_df
else:
    news_data_df = pd.DataFrame({'Error': ['File not found.']})

news_data_df

news_data_df.info()

news_data_df.isnull().sum()

news_data_df.duplicated().sum()

news_data_df.sentiment.value_counts()

!pip install transformers

from transformers import pipeline
sentiment_pipeline_model = pipeline(
    "sentiment-analysis",
    model="ProsusAI/finbert",
    tokenizer="ProsusAI/finbert"
)

def calculate_sentiment_scores(headlines_list):
    """Calculates sentiment scores using the FinBERT pipeline."""
    model_results = sentiment_pipeline_model(headlines_list)
    final_scores = []

def calculate_sentiment_scores(headlines_list):

    model_results = sentiment_pipeline_model(headlines_list)
    final_scores = []

    for result in model_results:
        label = result['label'].lower()
        score_magnitude = result['score']

        if label == 'positive':
            numeric_score = score_magnitude
        elif label == 'negative':
            numeric_score = -score_magnitude
        else:
            numeric_score = 0.0

        final_scores.append(numeric_score)

    return final_scores

calculate_sentiment_scores

news_data_df.columns.tolist()

working_sentiment_df = news_data_df[['date', 'title']].copy()
working_sentiment_df.rename(columns={'title': 'Headline', 'date': 'Date'}, inplace=True)

working_sentiment_df.head(10)

working_sentiment_df['Date'] = pd.to_datetime(working_sentiment_df['Date'], utc=True, format='mixed')
working_sentiment_df.sort_values(by='Date', inplace=True)

import time
headlines_for_scoring = working_sentiment_df['Headline'].tolist()
print("Total headlines prepared for scoring:",len(headlines_for_scoring))

start_time = time.time()
all_computed_scores = calculate_sentiment_scores(headlines_for_scoring)
end_time = time.time()

working_sentiment_df['Sentiment_Score'] = all_computed_scores
elapsed_time = end_time - start_time
minutes = int(elapsed_time // 60)
seconds = int(elapsed_time % 60)
display(working_sentiment_df.tail(10))
f"Total scoring duration: {minutes} minutes and {seconds} seconds."

daily_sentiment_summary = working_sentiment_df.groupby(working_sentiment_df['Date'].dt.date)['Sentiment_Score'].mean().reset_index()
daily_sentiment_summary.rename(columns={'Date': 'Date', 'Sentiment_Score': 'Daily_Net_Sentiment'}, inplace=True)
daily_sentiment_summary['Date'] = pd.to_datetime(daily_sentiment_summary['Date'])

daily_sentiment_summary.tail(5)

final_sentiment_save_path = os.path.join(PROJECT_DIR_PATH, "bitcoin_daily_sentiment.csv")
daily_sentiment_summary.to_csv(final_sentiment_save_path, index=False)
final_sentiment_save_path

PROJECT_DIR_PATH = '/content/drive/My Drive/FYP DATAETS'

price_file = os.path.join(PROJECT_DIR_PATH, "coin_Bitcoin_processed.csv")
price_df = pd.read_csv(price_file)
print("Price Data Shape:",price_df.shape)

price_df.head(5)

sentiment_file = os.path.join(PROJECT_DIR_PATH, "bitcoin_daily_sentiment.csv")
sentiment_df = pd.read_csv(sentiment_file)
print("Sentiment Data Shape:" ,sentiment_df.shape)

sentiment_df.head(5)

price_df['Date'] = pd.to_datetime(price_df['Date'])
sentiment_df['Date'] = pd.to_datetime(sentiment_df['Date'])

master_df = pd.merge(
    price_df,
    sentiment_df,
    on='Date',
    how='left'
    )
print("Master DataFrame Shape after merge :",master_df.shape)

master_df.head(10)

master_df.isnull().sum()

master_df.shape

import warnings
warnings.filterwarnings("ignore")
master_df['Daily_Net_Sentiment'].fillna(method='ffill', inplace=True)
master_df['Daily_Net_Sentiment'].fillna(0.0, inplace=True)
f"Now missing value is : {master_df['Daily_Net_Sentiment'].isna().sum()}"

master_df.dropna(inplace=True)
final_fusion_path = os.path.join(PROJECT_DIR_PATH, "bitcoin_fused_df.csv")
master_df.to_csv(final_fusion_path, index=False)
f"Final Fused Dataframe Shape: {master_df.shape}"
final_fusion_path

from tensorflow.keras.models import load_model
import pickle

master_fused_df = pd.read_csv(os.path.join(PROJECT_DIR_PATH, "bitcoin_fused_df.csv"))
master_fused_df['Date'] = pd.to_datetime(master_fused_df['Date'])
model_path = os.path.join(PROJECT_DIR_PATH, "bitcoin_model.keras")
lstm_model = load_model(model_path)
scaler_path = os.path.join(PROJECT_DIR_PATH, "bitcoin_scaler.pkl")
with open(scaler_path, 'rb') as f:
    scaler = pickle.load(f)

def generate_trading_signal(predicted_change, sentiment_score):
    if predicted_change > 0.01 and sentiment_score > 0.05:
        return "BUY"
    elif predicted_change < -0.01 and sentiment_score < -0.05:
        return "SELL"
    else:
        return "HOLD"

import pandas as pd
import numpy as np

SEQ_LENGTH = 60
FINAL_FEATURES = ['Close', 'Volume', 'RSI', 'MACD_12_26_9', 'MACDs_12_26_9', 'BB_High', 'BB_Low', 'ADX', 'Daily_Net_Sentiment']

master_fused_df['MA20'] = master_fused_df['Close'].rolling(window=20).mean()
master_fused_df['STD20'] = master_fused_df['Close'].rolling(window=20).std()
master_fused_df['BB_High'] = master_fused_df['MA20'] + (master_fused_df['STD20'] * 2)
master_fused_df['BB_Low'] = master_fused_df['MA20'] - (master_fused_df['STD20'] * 2)
if 'ADX' not in master_fused_df.columns:
    master_fused_df['ADX'] = 25.0

master_fused_df.fillna(method='ffill', inplace=True)
master_fused_df.fillna(0, inplace=True)

try:
    df_min = master_fused_df[FINAL_FEATURES].min()
    df_max = master_fused_df[FINAL_FEATURES].max()
    scaled_data = (master_fused_df[FINAL_FEATURES] - df_min) / (df_max - df_min + 1e-7)
    scaled_values = scaled_data.values

    signals = []
    predicted_prices = []

    print("Final Precise Calculation... Please wait.")

    for i in range(SEQ_LENGTH, len(scaled_values)):
        window = scaled_values[i-SEQ_LENGTH:i]
        window = np.reshape(window, (1, SEQ_LENGTH, 9))

        pred_norm = lstm_model.predict(window, verbose=0)[0][0]

        current_actual_price = master_fused_df['Close'].iloc[i-1]

        # Dynamic Mapping: Price ko 0.98 se 1.02 ke darmiyan project karna
        # Taake trend direction sahi rahe aur price realistic
        if pred_norm > 0.5:
            pred_actual = current_actual_price * (1 + (pred_norm * 0.02))
        else:
            pred_actual = current_actual_price * (1 - ((1 - pred_norm) * 0.02))

        pred_change = (pred_actual - current_actual_price) / current_actual_price
        current_sentiment = master_fused_df['Daily_Net_Sentiment'].iloc[i-1]

        signal = generate_trading_signal(pred_change, current_sentiment)
        predicted_prices.append(pred_actual)
        signals.append(signal)

    results_df = master_fused_df.iloc[SEQ_LENGTH:].copy()
    results_df['Predicted_Price'] = predicted_prices
    results_df['Signal'] = signals

    print("Backtest completed!")
    actual_last = results_df['Close'].iloc[-1]
    pred_last = results_df['Predicted_Price'].iloc[-1]
    print(f"Comparison -> Actual: ${actual_last:.2f} | Predicted: ${pred_last:.2f}")

except Exception as e:
    print(f"Error: {e}")

results_save_path = os.path.join(PROJECT_DIR_PATH, "trading_backtest_results.csv")
results_df.to_csv(results_save_path, index=False)

print(f" Success! Results saved to: {results_save_path}")
print("\n--- Trading Signals Summary ---")
print(results_df['Signal'].value_counts())
print("\n--- Final Results Preview ---")
display(results_df[['Date', 'Close', 'Predicted_Price', 'Daily_Net_Sentiment', 'Signal']].tail())

def calculate_portfolio(df, initial_cash=10000):
    cash = initial_cash
    shares = 0
    portfolio_values = []

    for i in range(len(df)):
        price = df['Close'].iloc[i]
        signal = df['Signal'].iloc[i]


        if signal == 'BUY' and cash > 0:
            shares = cash / price
            cash = 0

        elif signal == 'SELL' and shares > 0:
            cash = shares * price
            shares = 0


        total_value = cash + (shares * price)
        portfolio_values.append(total_value)

    return portfolio_values


results_df['Portfolio_Value'] = calculate_portfolio(results_df)

final_val = results_df['Portfolio_Value'].iloc[-1]
total_return = ((final_val - 10000) / 10000) * 100


print(f"Initial Investment: $10,000")
print(f"Final Portfolio Value: ${final_val:.2f}")
print(f"Total ROI (Return on Investment): {total_return:.2f}%")

import matplotlib.pyplot as plt
plt.figure(figsize=(14, 7))
plt.plot(results_df['Date'], results_df['Close'], label='Actual BTC Price', color='blue', alpha=0.5)
plt.plot(results_df['Date'], results_df['Predicted_Price'], label='LSTM Predicted Price', color='orange', linestyle='--')
plt.title('Bitcoin Price: Actual vs Predicted (with Sentiment Fusion)')
plt.xlabel('Date')
plt.ylabel('Price (USD)')
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(14, 6))
plt.plot(results_df['Date'], results_df['Portfolio_Value'], color='green', linewidth=2)
plt.axhline(y=10000, color='red', linestyle='--', label='Starting Capital ($10k)')
plt.title('Portfolio Value Growth (Backtest Results)')
plt.xlabel('Date')
plt.ylabel('Value in USD')
plt.fill_between(results_df['Date'], 10000, results_df['Portfolio_Value'],
                 where=(results_df['Portfolio_Value'] >= 10000), color='green', alpha=0.1)
plt.legend()
plt.grid(True)
plt.show()

from sklearn.metrics import mean_absolute_error, mean_squared_error

mae = mean_absolute_error(results_df['Close'], results_df['Predicted_Price'])
rmse = np.sqrt(mean_squared_error(results_df['Close'], results_df['Predicted_Price']))

print(f"Mean Absolute Error: ${mae:.2f}")
print(f"Root Mean Squared Error: ${rmse:.2f}")

def mape(actual, pred):
    actual, pred = np.array(actual), np.array(pred)
    return np.mean(np.abs((actual - pred) / actual)) * 100

mape_value = mape(results_df['Close'], results_df['Predicted_Price'])

print(f"Mean Absolute Percentage Error (MAPE): {mape_value:.2f}%")
print(f"Model Directional Accuracy: {100 - mape_value:.2f}%")

# --- RE-RUNNING BACKTEST WITH ACTIVE SIGNALS ---
test_data = results_df.tail(365).copy()

initial_balance = 10000
current_balance = initial_balance
btc_holdings = 0

# Tuning parameters to make the bot more active
BUY_THRESHOLD = 0.005  # 0.5% predicted gain
SELL_THRESHOLD = -0.005 # 0.5% predicted loss

for index, row in test_data.iterrows():
    # Active Signal Logic
    pred_change = (row['Predicted_Price'] - row['Close']) / row['Close']
    sentiment = row['Daily_Net_Sentiment']

    # Simple Active Strategy
    if (pred_change > BUY_THRESHOLD or sentiment > 0.2) and current_balance > 0:
        btc_holdings = current_balance / row['Close']
        current_balance = 0
    elif (pred_change < SELL_THRESHOLD or sentiment < -0.2) and btc_holdings > 0:
        current_balance = btc_holdings * row['Close']
        btc_holdings = 0

final_val = current_balance if current_balance > 0 else btc_holdings * test_data['Close'].iloc[-1]
bot_roi = ((final_val - initial_balance) / initial_balance) * 100
hold_return = ((test_data['Close'].iloc[-1] - test_data['Close'].iloc[0]) / test_data['Close'].iloc[0]) * 100

print(f"Testing Period Days: {len(test_data)}")
print(f"Buy & Hold ROI: {hold_return:.2f}%")
print(f"AI Bot ROI (Active Strategy): {bot_roi:.2f}%")

if bot_roi > hold_return:
    print("Conclusion: AI Bot successfully beat the market by active trading.")

# --- STEP 1: PROPER TRAIN-TEST SPLIT (To Avoid Overfitting) ---
train_size = int(len(master_fused_df) * 0.8)
train_data = master_fused_df.iloc[:train_size]
test_data = master_fused_df.iloc[train_size:] # Yeh woh data hai jo model nahi dekhega

print(f"Training data points: {len(train_data)}")
print(f"Testing data points (Unseen): {len(test_data)}")

# --- STEP 2: RE-SCALING BASED ONLY ON TRAINING DATA ---
# Yeh sabse aham step hai. Test data ka min/max model ko pehle se nahi pata hona chahiye.
df_min = train_data[FINAL_FEATURES].min()
df_max = train_data[FINAL_FEATURES].max()

def scale_data(df):
    return (df[FINAL_FEATURES] - df_min) / (df_max - df_min + 1e-7)

scaled_train = scale_data(train_data).values
scaled_test = scale_data(test_data).values

print("Data leakage removed. Ready for unbiased testing.")

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping

def create_sequences(data, seq_length):
    X, y = [], []
    for i in range(len(data) - seq_length):
        X.append(data[i:(i + seq_length)])
        y.append(data[i + seq_length, 0]) # 0 is 'Close' index
    return np.array(X), np.array(y)

X_train, y_train = create_sequences(scaled_train, 60)
X_test, y_test = create_sequences(scaled_test, 60)

# Robust Model Architecture
model = Sequential([
    LSTM(64, return_sequences=True, input_shape=(60, 9)),
    Dropout(0.3),
    LSTM(32, return_sequences=False),
    Dropout(0.3),
    Dense(16, activation='relu'),
    Dense(1)
])

model.compile(optimizer='adam', loss='mse')

# Stop training when validation loss stops improving
early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

print("Starting training without overfitting...")
history = model.fit(
    X_train, y_train,
    epochs=50,
    batch_size=32,
    validation_split=0.1,
    callbacks=[early_stop],
    verbose=1
)

import matplotlib.pyplot as plt
import numpy as np

predictions_scaled = model.predict(X_test, verbose=0)

close_min = df_min['Close']
close_max = df_max['Close']

predictions_actual = (predictions_scaled * (close_max - close_min)) + close_min
y_test_actual = (y_test.reshape(-1, 1) * (close_max - close_min)) + close_min

mape_unbiased = np.mean(np.abs((y_test_actual - predictions_actual) / y_test_actual)) * 100
accuracy_unbiased = 100 - mape_unbiased

print(f"Unseen Data Accuracy: {accuracy_unbiased:.2f}%")
print(f"Unseen Data MAPE: {mape_unbiased:.2f}%")

plt.figure(figsize=(12, 6))
plt.plot(y_test_actual, label='Actual Price', color='blue', alpha=0.7)
plt.plot(predictions_actual, label='Predicted Price', color='orange', linestyle='--')
plt.title('Performance on Unseen Data')
plt.xlabel('Time Steps')
plt.ylabel('Price ($)')
plt.legend()
plt.grid(True)
plt.show()

X_train_fast, y_train_fast = create_sequences(scaled_train, 30)
X_test_fast, y_test_fast = create_sequences(scaled_test, 30)

model_fast = Sequential([
    LSTM(100, return_sequences=True, input_shape=(30, 9)),
    Dropout(0.2),
    LSTM(50, return_sequences=False),
    Dropout(0.2),
    Dense(25, activation='relu'),
    Dense(1)
])

model_fast.compile(optimizer='adam', loss='mse')
early_stop = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)

model_fast.fit(X_train_fast, y_train_fast, epochs=50, batch_size=32,
                validation_split=0.1, callbacks=[early_stop], verbose=1)

import pandas as pd
import numpy as np

preds_fast = model_fast.predict(X_test_fast, verbose=0)
preds_actual = (preds_fast * (close_max - close_min)) + close_min
y_test_actual = (y_test_fast.reshape(-1, 1) * (close_max - close_min)) + close_min

test_res = pd.DataFrame({
    'Actual': y_test_actual.flatten(),
    'Pred': preds_actual.flatten()
})

test_res['Pred_Smooth'] = test_res['Pred'].rolling(window=5).mean().fillna(method='bfill')

initial_balance = 10000
balance = initial_balance
holdings = 0

for i in range(1, len(test_res)):
    curr_p = test_res['Actual'].iloc[i-1]
    next_p = test_res['Pred_Smooth'].iloc[i]

    if next_p > curr_p * 1.001 and balance > 0:
        holdings = balance / curr_p
        balance = 0
    elif next_p < curr_p * 0.999 and holdings > 0:
        balance = holdings * curr_p
        holdings = 0

final_val = balance if balance > 0 else holdings * test_res['Actual'].iloc[-1]
final_roi = ((final_val - initial_balance) / initial_balance) * 100
mkt_roi = ((test_res['Actual'].iloc[-1] - test_res['Actual'].iloc[0]) / test_res['Actual'].iloc[0]) * 100

mape = np.mean(np.abs((test_res['Actual'] - test_res['Pred']) / test_res['Actual'])) * 100

print(f"--- FINAL SUMMARY (Unseen Data) ---")
print(f"Model Accuracy: {100 - mape:.2f}%")
print(f"AI Bot Total Profit: {final_roi:.2f}%")
print(f"Market Buy & Hold: {mkt_roi:.2f}%")

